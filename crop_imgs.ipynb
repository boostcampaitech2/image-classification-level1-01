{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cb29a0f-051d-42ff-ac4e-bc4680f37c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install cMake\n",
    "# !conda install -c conda-forge dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1fba2c9-1609-41fa-ab9f-d76593393a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from facenet_pytorch import MTCNN\n",
    "import os, cv2, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c98c3536-d893-4221-9416-160e026dfe28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a29a544e-8a1e-4e25-88db-5f3fcf1ea74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### MTCNN ####################\n",
    "\n",
    "mtcnn = MTCNN(keep_all=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66edd861-548f-434b-849b-66f099ee5a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2700/2700 [10:42<00:00,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#################### CROP_TRAIN_IMGS ####################\n",
    "\n",
    "new_img_dir = './input/data/train/new_imgs'\n",
    "img_path = './input/data/train/images'\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for paths in tqdm.tqdm(os.listdir(img_path)):\n",
    "    if paths[0] == '.': continue\n",
    "    \n",
    "    sub_dir = os.path.join(img_path, paths)\n",
    "    \n",
    "    for imgs in os.listdir(sub_dir):\n",
    "        if imgs[0] == '.': continue\n",
    "        img_dir = os.path.join(sub_dir, imgs)\n",
    "        img = cv2.imread(img_dir)\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        #mtcnn 적용\n",
    "        boxes, probs = mtcnn.detect(img)\n",
    "        \n",
    "        # boxes 확인\n",
    "#         if len(probs) > 1: \n",
    "#             print(boxes)\n",
    "        if not isinstance(boxes, np.ndarray):\n",
    "#             print('Nope!')\n",
    "            # 직접 crop\n",
    "            img = img[100:400, 50:350, :]\n",
    "        \n",
    "        # boexes size 확인\n",
    "        else:\n",
    "            xmin = int(boxes[0, 0]) - 15\n",
    "            ymin = int(boxes[0, 1]) - 15\n",
    "            xmax = int(boxes[0, 2]) + 15\n",
    "            ymax = int(boxes[0, 3]) + 15\n",
    "            \n",
    "            if xmin < 0: xmin = 0\n",
    "            if ymin < 0: ymin = 0\n",
    "            if xmax > 384: xmax = 384\n",
    "            if ymax > 512: ymax = 512\n",
    "            \n",
    "            img = img[ymin:ymax, xmin:xmax, :]\n",
    "            \n",
    "        tmp = os.path.join(new_img_dir, paths)\n",
    "        plt.imsave(os.path.join(tmp, imgs), img)\n",
    "        cnt += 1\n",
    "        \n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d0b239d-9eea-493d-ba20-fdae6cb30abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12600/12600 [07:32<00:00, 27.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#################### CROP_EVAL_IMGS ####################\n",
    "\n",
    "test_info = pd.read_csv('./input/data/eval/info.csv')\n",
    "path = './input/data/eval/images'\n",
    "new_path = './input/data/eval/new_imgs'\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "if not os.path.exists(new_path):\n",
    "    os.mkdir(new_path)\n",
    "    \n",
    "for i in tqdm.tqdm(test_info.values):\n",
    "    img = cv2.imread(os.path.join(path, i[0]))\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #mtcnn 적용\n",
    "    boxes, probs = mtcnn.detect(img)\n",
    "    \n",
    "    # boxes 확인\n",
    "    if not isinstance(boxes, np.ndarray):\n",
    "#         print('Nope!')\n",
    "        # 직접 crop\n",
    "        img = img[100:400, 50:350, :]\n",
    "    \n",
    "    # boexes size 확인\n",
    "    else:\n",
    "        xmin = int(boxes[0, 0]) - 15\n",
    "        ymin = int(boxes[0, 1]) - 15\n",
    "        xmax = int(boxes[0, 2]) + 15\n",
    "        ymax = int(boxes[0, 3]) + 15\n",
    "        \n",
    "        if xmin < 0: xmin = 0\n",
    "        if ymin < 0: ymin = 0\n",
    "        if xmax > 384: xmax = 384\n",
    "        if ymax > 512: ymax = 512\n",
    "        \n",
    "        img = img[ymin:ymax, xmin:xmax, :]\n",
    "        \n",
    "    plt.imsave(os.path.join(new_path, i[0]), img)\n",
    "    cnt += 1\n",
    "    \n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a58b346-9564-4a0c-bc02-d40c91d2a4a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
