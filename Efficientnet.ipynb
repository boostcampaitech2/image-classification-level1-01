{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1685ea9-b565-4f29-9deb-9466bdbfe461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -c conda-forge opencv\n",
    "# !pip install tqdm\n",
    "# !pip install -U albumentations\n",
    "# !pip install efficientnet_pytorch\n",
    "# !pip install ipywidgets\n",
    "# !jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdb7e31-71ae-42e8-8719-6bbe6b6e32fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "import os, random, time, copy, tqdm, cv2, re\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.autograd import Variable\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0ef3b7-89cf-4048-bdb7-1457c2e4ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "!free -mh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a16616-3cac-4837-a097-2e00f0f7be85",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e610a6-5aa9-4510-92b2-efc33df2ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./input/data/train/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23a20d9-873c-43fa-950b-e886fd13445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402a203d-2796-41f7-bc47-664e83b261e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69278075-272d-48bb-b7ad-36f8bfb94fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c92ee65-9e58-4779-84f2-afec88466aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### testing...\n",
    "\n",
    "def age(x):\n",
    "    if x<30:\n",
    "        return 0\n",
    "#     elif x<60:\n",
    "    elif x<59:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "# age: <30: 0, >=30, <60: 1, >=60: 2\n",
    "### age: <30: 0, >=30, <58: 1, >=59: 2\n",
    "train['age'] = train['age'].apply(lambda x: age(x))\n",
    "\n",
    "# gender: female: 0, male: 1\n",
    "train['gender'] = train['gender'].map({'female': 0, 'male': 1})\n",
    "\n",
    "# 불필요한 race 삭제\n",
    "train = train.drop(['race'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee0ab4c-ad77-41a0-a2a3-511606756322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix gedner error in person\n",
    "# gender: female: 0, male: 1\n",
    "\n",
    "for i in range(len(train)):\n",
    "    # male => female\n",
    "    if train.iloc[i, 3] in ['004432_male_Asian_43','001498-1_male_Asian_23']:\n",
    "        train.iloc[i, 1] = 0\n",
    "        print(train.iloc[i])\n",
    "        \n",
    "    # female => male\n",
    "    elif train.iloc[i, 3] in ['006359_female_Asian_18','006360_female_Asian_18',\n",
    "                              '006361_female_Asian_18','006362_female_Asian_18',\n",
    "                              '006363_female_Asian_18','006364_female_Asian_18']:\n",
    "        train.iloc[i, 1] = 1\n",
    "        print(train.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80fb358-3f17-469f-b390-5aec59bf5d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_mask_data(data_path):\n",
    "    '''\n",
    "    Create a new table with labeled path and mask.\n",
    "    '''\n",
    "    data = {'path': [], 'mask': []}\n",
    "\n",
    "    for labels in os.listdir(data_path):\n",
    "        label = None\n",
    "        if labels[:2] == '._': continue # skip trash\n",
    "        sub = os.path.join(data_path, labels)\n",
    "        \n",
    "        # mask: normal: 0, incorrect: 1, mask: 2\n",
    "        for img in os.listdir(sub):\n",
    "            if img[0] == '.': continue # skip trash\n",
    "            if img.find('normal') != -1:\n",
    "                label = 0\n",
    "            elif img.find('incorrect') != -1:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 2\n",
    "            data['path'].append(os.path.join(sub, img)) # save path\n",
    "            data['mask'].append(label) # save mask\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c380d5-c48b-49cb-9008-351337e190f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_age_gender_data(data):\n",
    "    '''\n",
    "    Create a new table with labeled age and gender.\n",
    "    '''\n",
    "    tmp = {'age': [], 'gender': []}\n",
    "\n",
    "    for index, i in enumerate(data.iloc[:, 0].values):\n",
    "        classes = i.split('/')[-2]\n",
    "#         print(classes)\n",
    "        for idx in train.values:\n",
    "#             print(idx[3])\n",
    "            if classes == idx[3]:\n",
    "                tmp['gender'].append(idx[1])\n",
    "                tmp['age'].append(idx[2])\n",
    "                \n",
    "    return pd.DataFrame(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a1e14e-bf68-4475-a9f6-5e170d99ed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# order in [mask, age, gender]\n",
    "data = prepare_mask_data('./input/data/train/images')\n",
    "labels = prepare_age_gender_data(data)\n",
    "data = pd.concat([data, labels['age'], labels['gender']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7cb190-6442-4121-9bae-2c44cd05d2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10dd2f3-e63f-4c7d-93fa-4bf277fe4282",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356022e2-f2a3-4d4d-bd9d-e5f33f41d816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix mask and gender error in img\n",
    "# mask: normal: 0, incorrect: 1, mask: 2\n",
    "# gender: female: 0, male: 1\n",
    "\n",
    "url = './input/data/train/images/'\n",
    "\n",
    "for i in range(len(data)):\n",
    "    # normal => incorrect\n",
    "    if data.iloc[i,0] in [url+'000020_female_Asian_50/normal.jpg',\n",
    "                          url+'004418_male_Asian_20/normal.jpg',\n",
    "                          url+'005227_male_Asian_22/normal.jpg']:\n",
    "            data.iloc[i,1] = 0\n",
    "            print(data.iloc[i, 0])\n",
    "            print(data.iloc[i])\n",
    "            \n",
    "    # incorrect => normal\n",
    "    elif data.iloc[i,0] in [url+'000020_female_Asian_50/incorrect_mask.jpg',\n",
    "                            url+'004418_male_Asian_20/incorrect_mask.jpg',\n",
    "                            url+'005227_male_Asian_22/incorrect_mask.jpg']:\n",
    "            data.iloc[i,1] = 1\n",
    "            print(data.iloc[i, 0])\n",
    "            print(data.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a50fb20-9dca-44de-af58-a502fdddfdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask, age, gender Bar Plot\n",
    "\n",
    "mask_label = data['mask'].value_counts().sort_index()\n",
    "age_label = data['age'].value_counts().sort_index()\n",
    "gender_label = data['gender'].value_counts().sort_index()\n",
    "\n",
    "plt.figure(dpi=200)\n",
    "fig = plt.figure(figsize=(20, 7))\n",
    "\n",
    "ax_mask = fig.add_subplot(1, 3, 1)\n",
    "ax_age = fig.add_subplot(1, 3, 2)\n",
    "ax_gender = fig.add_subplot(1, 3, 3)\n",
    "\n",
    "\n",
    "# Mask\n",
    "ax_mask.bar(['Normal', 'Incorrect', 'Mask'], mask_label, zorder=10)\n",
    "    \n",
    "for index, val in mask_label.iteritems():\n",
    "    ax_mask.text(x=index, y=val+100, s=val,\n",
    "                 va='bottom', ha='center',\n",
    "                 fontsize=12, fontweight='bold'\n",
    "                )\n",
    "\n",
    "# Age\n",
    "ax_age.bar(['- 29', '30-58', '59 - '], age_label/7, zorder=10)\n",
    "    \n",
    "for index, val in age_label.iteritems():\n",
    "    ax_age.text(x=index, y=val/7+20, s=int(val/7),\n",
    "                 va='bottom', ha='center',\n",
    "                 fontsize=12, fontweight='bold'\n",
    "                )\n",
    "\n",
    "# Gender\n",
    "ax_gender.bar(['Female', 'Male'], gender_label/7, color=['tomato', 'royalblue'], zorder=10)\n",
    "\n",
    "for index, value in zip(gender_label.index, gender_label):\n",
    "    ax_gender.text(index, value/7+20, s=int(value/7),\n",
    "                   va='bottom', ha='center',\n",
    "                   fontsize=12, fontweight='bold'\n",
    "                  )\n",
    "\n",
    "    \n",
    "idx = np.arange(len(mask_label.index))\n",
    "\n",
    "ax_mask.margins(0.1, 0.1)\n",
    "ax_mask.set_title('Mask', fontsize=15, fontweight='bold')\n",
    "ax_mask.grid(zorder=0, axis='y')\n",
    "    \n",
    "ax_age.margins(0.1, 0.1)\n",
    "ax_age.set_title('Age', fontsize=15, fontweight='bold')\n",
    "ax_age.grid(zorder=0, axis='y')\n",
    "    \n",
    "ax_gender.margins(0.1, 0.1)\n",
    "ax_gender.set_title('Gender', fontsize=15, fontweight='bold')\n",
    "ax_gender.grid(zorder=0, axis='y')\n",
    "\n",
    "for s in ['top', 'right', 'left']:\n",
    "    ax_mask.spines[s].set_visible(False)\n",
    "    ax_age.spines[s].set_visible(False)\n",
    "    ax_gender.spines[s].set_visible(False)\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230477f4-24a8-445b-b522-0e6b4a0407e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### CROP_NEW_IMG ####################\n",
    "\n",
    "for idx, i in enumerate(data.values):\n",
    "    tmp = i[0]\n",
    "    tmp = re.sub('images', 'new_imgs', tmp)\n",
    "    data.iloc[idx, 0] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd17c36-a35f-4f45-b1d1-bde6bd2e51ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename to avoid confusion\n",
    "label_df = data\n",
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de530bf9-85b4-4615-83c2-e6c41ce0a8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### MASK_AGE_GENDER_DATASETS ####################\n",
    "\n",
    "class mask_dataset(Dataset):\n",
    "    def __init__(self, data, index=None, transforms=None):\n",
    "        self.index = index\n",
    "        self.data = data.iloc[self.index]\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        label = int(self.data.iloc[index, 1]) #########\n",
    "        \n",
    "        img_path = self.data.iloc[index, 0]\n",
    "        img = cv2.imread(img_path)\n",
    "        # opencv: BGR\n",
    "        # matplotlib: RGB\n",
    "        image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image=image)['image']\n",
    "        # opencv cv2.imread(): [height, width, channels]\n",
    "        # pytorch: [channels, height, width]\n",
    "        # H, W, C => C, H, W\n",
    "        image = image.transpose((2,0,1))\n",
    "        sample = {'image': image, 'label': label}\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "\n",
    "class age_dataset(Dataset):\n",
    "    def __init__(self, data, index=None, transforms=None):\n",
    "        self.index = index\n",
    "        self.data = data.iloc[self.index]\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        label = int(self.data.iloc[index, 2]) #########\n",
    "        \n",
    "        img_path = self.data.iloc[index, 0]\n",
    "        img = cv2.imread(img_path)\n",
    "        # opencv: BGR\n",
    "        # matplotlib: RGB\n",
    "        image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image=image)['image']\n",
    "        # opencv cv2.imread(): [height, width, channels]\n",
    "        # pytorch: [channels, height, width]\n",
    "        # H, W, C => C, H, W\n",
    "        image = image.transpose((2,0,1))\n",
    "        sample = {'image': image, 'label': label}\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "\n",
    "class gender_dataset(Dataset):\n",
    "    def __init__(self, data, index=None, transforms=None):\n",
    "        self.index = index\n",
    "        self.data = data.iloc[self.index]\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        label = int(self.data.iloc[index, 3]) #########\n",
    "        \n",
    "        img_path = self.data.iloc[index, 0]\n",
    "        img = cv2.imread(img_path)\n",
    "        # opencv: BGR\n",
    "        # matplotlib: RGB\n",
    "        image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image=image)['image']\n",
    "        # opencv cv2.imread(): [height, width, channels]\n",
    "        # pytorch: [channels, height, width]\n",
    "        # H, W, C => C, H, W\n",
    "        image = image.transpose((2,0,1))\n",
    "        sample = {'image': image, 'label': label}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ef9758-bf7e-4128-bdac-11aa87ba6f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### AUGMENTATION ####################\n",
    "# https://brunokrinski.github.io/awesome-data-augmentation/\n",
    "# https://hoya012.github.io/blog/albumentation_tutorial/\n",
    "# https://albumentations-demo.herokuapp.com/\n",
    "\n",
    "# Data Augmentation, Normalization, Resize\n",
    "# 학습을 위한 데이터 증가 및 일반화, 사이즈 조절\n",
    "# 검증을 위한 일반화, 사이즈 조절\n",
    "\n",
    "# mask transforms\n",
    "mask_transforms = A.Compose([\n",
    "\n",
    "    A.OneOf([\n",
    "        A.RandomBrightness(p=1.0),\n",
    "        A.HueSaturationValue(p=1.0),\n",
    "        A.RandomContrast(p=1.0),\n",
    "    ], p=0.5),\n",
    "    \n",
    "    A.OneOf([\n",
    "        A.Perspective(p=1.0),\n",
    "        A.Rotate(p=0.5, limit=20, border_mode=1)\n",
    "    ], p=0.5),\n",
    "    \n",
    "    A.Compose([\n",
    "        A.Resize(312, 312),\n",
    "        A.Normalize()\n",
    "    ])\n",
    "])\n",
    "\n",
    "# age transforms\n",
    "age_transforms = A.Compose([\n",
    "\n",
    "    A.OneOf([\n",
    "        A.RandomGridShuffle(grid=(2, 2), p=1.0),\n",
    "        A.Perspective(p=1.0)\n",
    "    ], p=0.5),\n",
    "    \n",
    "    A.GaussNoise(p=0.5),\n",
    "    A.Rotate(limit=20, p=0.5, border_mode=1),\n",
    "\n",
    "    A.Compose([\n",
    "        A.Resize(312, 312),\n",
    "        A.Normalize()\n",
    "    ])\n",
    "])\n",
    "\n",
    "# gender transforms\n",
    "gender_transforms = A.Compose([\n",
    "\n",
    "    A.OneOf([\n",
    "        A.Perspective(p=1.0)\n",
    "    ], p=0.5),\n",
    "    \n",
    "    A.GaussNoise(p=0.5),\n",
    "    A.Rotate(limit=20, p=0.5, border_mode=1),\n",
    "\n",
    "    A.Compose([\n",
    "        A.Resize(312, 312),\n",
    "        A.Normalize()\n",
    "    ])\n",
    "])\n",
    "\n",
    "# valid transforms\n",
    "valid_transforms = A.Compose([\n",
    "    A.Resize(312, 312),\n",
    "    A.Normalize(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6659afda-781e-477a-863d-fccdb971f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### RANDOMNESS ####################\n",
    "# https://hoya012.github.io/blog/reproducible_pytorch/\n",
    "\n",
    "def make_seed(seed):\n",
    "    '''\n",
    "    Set the seed of the random number generator to a fixed value.\n",
    "    Fixed values for reproducing results.\n",
    "    '''\n",
    "    torch.manual_seed(seed) # CPU 연산 무작위 고정\n",
    "    torch.cuda.manual_seed(seed) # GPU 연산 무작위 고정\n",
    "    torch.cuda.manual_seed_all(seed) # multi-GPU 연산 무작위 고정\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "seed = 777\n",
    "make_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d70a42-db21-4844-989c-3b5a802c1613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(20):\n",
    "#     print(f'{i:02d}: {data.iloc[i, 0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eac15d-447f-4892-b0ef-86cca82e626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### KFOLD ####################\n",
    "### testing...\n",
    "\n",
    "def get_index():\n",
    "    '''\n",
    "    KFold, Split indexes by people.\n",
    "    '''\n",
    "    label_idx = [i for i in range(2700)]\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=777)\n",
    "    train_num, valid_num = list(), list()\n",
    "    \n",
    "    for idx, (train_idx, valid_idx) in enumerate(kfold.split(label_idx)):\n",
    "#         print(idx)\n",
    "        train_idx = train_idx * 7\n",
    "        valid_idx = valid_idx * 7\n",
    "        train_tmp, valid_tmp = list(), list()\n",
    "        \n",
    "        for i in train_idx:\n",
    "            for j in range(7):\n",
    "                train_tmp.append(i + j)\n",
    "                \n",
    "        for i in valid_idx:\n",
    "            for j in range(7):\n",
    "                valid_tmp.append(i + j)\n",
    "                \n",
    "        train_num.append(train_tmp)\n",
    "        valid_num.append(valid_tmp)\n",
    "        \n",
    "    return train_num, valid_num\n",
    "\n",
    "\n",
    "def get_index_label():\n",
    "    '''\n",
    "    KFold, Split indexes by label.\n",
    "    '''\n",
    "    label_idx = [i for i in range(2700 * 7)]\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=777)\n",
    "    train_num, valid_num = list(), list()\n",
    "    \n",
    "    for idx, (train_idx, valid_idx) in enumerate(kfold.split(label_idx)):\n",
    "#         print(idx)\n",
    "        train_num.append(train_idx)\n",
    "        valid_num.append(valid_idx)\n",
    "        \n",
    "    return train_num, valid_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03403940-bc48-4fb3-af16-cde56af83e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a, b = get_index()\n",
    "# c, d = get_index_label()\n",
    "# print(f'a: {a}')\n",
    "# print(f'b: {b}')\n",
    "# print(f'c: {c}')\n",
    "# print(f'd: {d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c22a3a-d213-4a7e-add6-b20c58a5c22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### WEIGHT ####################\n",
    "# https://discuss.pytorch.org/t/weights-in-weighted-loss-nn-crossentropyloss/69514/2\n",
    "\n",
    "### testing...\n",
    "\n",
    "def normal_weights(data):\n",
    "    normed_weights=torch.FloatTensor([1-(x/sum(data))for x in data]).to(device)\n",
    "    return normed_weights\n",
    "\n",
    "weighted_mask = normal_weights([1, 1, 5])\n",
    "# weighted_age = normal_weights([1281,1227,192])\n",
    "weighted_age = normal_weights([1281,1142,277])\n",
    "weighted_gender = normal_weights([1654,1046])\n",
    "\n",
    "print(weighted_mask)\n",
    "print(weighted_age)\n",
    "print(weighted_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3a681c-0a51-4b28-b86f-89e79920934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### FOCALLOSS ####################\n",
    "# https://nuguziii.github.io/dev/dev-002/\n",
    "# https://ropiens.tistory.com/83\n",
    "# https://amaarora.github.io/2020/06/29/FocalLoss.html\n",
    "# https://wordbe.tistory.com/entry/ML-Cross-entropyCategorical-Binary%EC%9D%98-%EC%9D%B4%ED%95%B4\n",
    "# https://headbreakz.tistory.com/entry/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-Batch-Mini-Batch\n",
    "# https://anweh.tistory.com/21\n",
    "# https://wikidocs.net/60572\n",
    "# https://velog.io/@skyhelper/CrossEntorpyLoss-NLLLoss-%EB%AC%B4%EC%97%87%EC%9D%B4-%EB%8B%A4%EB%A5%B8%EA%B0%80\n",
    "# http://www.gisdeveloper.co.kr/?p=8668\n",
    "# https://pytorch.org/docs/1.9.0/generated/torch.nn.functional.nll_loss.html\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None,\n",
    "                 gamma=2., reduction='mean'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        log_prob = F.log_softmax(input_tensor, dim=-1)\n",
    "        prob = torch.exp(log_prob)\n",
    "        return F.nll_loss(\n",
    "            ((1 - prob) ** self.gamma) * log_prob,\n",
    "            target_tensor,\n",
    "            weight=self.weight,\n",
    "            reduction=self.reduction\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0296470b-27a1-431e-b45a-80b13b538483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### TRAIN_MASK ####################\n",
    "\n",
    "### EfficientNet ###\n",
    "# https://github.com/lukemelas/EfficientNet-PyTorch\n",
    "# https://hoya012.github.io/blog/EfficientNet-review/\n",
    "# https://keep-steady.tistory.com/35\n",
    "\n",
    "### Learning rate Scheduler ###\n",
    "# https://sanghyu.tistory.com/113\n",
    "# https://sungwookkang.com/1415\n",
    "# https://zsunn.tistory.com/entry/AI-%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EC%9A%94-%EC%88%9C%EC%A0%84%ED%8C%8C-%EC%97%AD%EC%A0%84%ED%8C%8C-%EA%B7%B8%EB%A6%AC%EA%B3%A0-%ED%99%9C%EC%84%B1%ED%99%94-%ED%95%A8%EC%88%98\n",
    "# https://wikidocs.net/37406\n",
    "# https://deep-deep-deep.tistory.com/56\n",
    "\n",
    "### F1-Score ###\n",
    "# https://datascienceschool.net/03%20machine%20learning/09.04%20%EB%B6%84%EB%A5%98%20%EC%84%B1%EB%8A%A5%ED%8F%89%EA%B0%80.html\n",
    "# https://brunch.co.kr/@chris-song/54\n",
    "# https://eunsukimme.github.io/ml/2019/10/21/Accuracy-Recall-Precision-F1-score/\n",
    "\n",
    "### transfer learning & fine tuning ###\n",
    "# https://hyjykelly.tistory.com/50\n",
    "# https://velog.io/@yookyungkho/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%98-%EA%B3%A0%EC%A7%88%EB%B3%91-Overfitting%EA%B3%BC%EC%A0%81%ED%95%A9-%ED%95%B4%EA%B2%B0-%ED%8C%81\n",
    "# https://inhovation97.tistory.com/31\n",
    "# https://jungnamgyu.tistory.com/34\n",
    "# https://inhovation97.tistory.com/32\n",
    "\n",
    "\n",
    "def train_mask(num_epochs=10, batch_size=16, learnig_rate=3e-4, ef_net='efficientnet-b4', nums=i):\n",
    "    writer = SummaryWriter(log_dir=f'./results/b3_mask_64_1e_2-{nums}')\n",
    "#     writer = SummaryWriter(log_dir=f'./results/pp_b3_mask_64_1e_7-{nums}')\n",
    "    \n",
    "    best_loss = 100\n",
    "#     best_f1 = 0.0\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(weight=weighted_mask).to(device)\n",
    "    \n",
    "    # 모델(구조)만 가져오기\n",
    "    # model_mask = EfficientNet.from_name(ef_net, num_classes=3).to(device)\n",
    "    # 이미 학습된 weight까지 가져오기\n",
    "    # num_classes: 데이터 분류 사이즈\n",
    "    model_mask = EfficientNet.from_pretrained(ef_net, num_classes=3).to(device)\n",
    "    optimizer_mask = optim.Adam(model_mask.parameters(), lr=learnig_rate)\n",
    "    \n",
    "    # 성능 향상 없을 때, learning rate 감소\n",
    "    # scheduler = optim.lr_scheduler.StepLR(optimizer_mask, step_size=3, gamma=0.1)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer_mask, mode='min', factor=0.2, patience=3\n",
    "    )\n",
    "\n",
    "    # KFold\n",
    "#     kfold = KFold(n_splits=5, shuffle=True)\n",
    "#     for fold, [train_ids, valid_ids] in enumerate(kfold.split(label_df)):\n",
    "#         if fold==1:\n",
    "#             return model_mask.state_dict()\n",
    "\n",
    "#     train_ids, valid_ids = get_index()\n",
    "    train_ids, valid_ids = get_index_label()\n",
    "\n",
    "#     train_data = mask_dataset(label_df, index=[train_ids], transforms=mask_transforms)\n",
    "#     valid_data = mask_dataset(label_df, index=valid_ids, transforms=valid_transforms)\n",
    "    train_data = mask_dataset(label_df, index=[i for i in range(2700*7)], transforms=mask_transforms)\n",
    "    valid_data = mask_dataset(label_df, index=valid_ids[4], transforms=valid_transforms)\n",
    "\n",
    "    # RandomSampler: Samples elements randomly\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    valid_sampler = RandomSampler(valid_data)\n",
    "\n",
    "    # num_workers: 데이터 로드 멀티 프로세싱\n",
    "    train_dataloader = DataLoader(\n",
    "        train_data, batch_size=batch_size,\n",
    "        shuffle=False, sampler=train_sampler, num_workers=4\n",
    "    )\n",
    "    valid_dataloader = DataLoader(\n",
    "        valid_data, batch_size=batch_size,\n",
    "        shuffle=False, sampler=valid_sampler, num_workers=4\n",
    "    )\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 20)\n",
    "\n",
    "        # 각 epoch: 학습 단게, 검증 단계\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                # 모델, 학습 모드 설정\n",
    "                model_mask.train()\n",
    "\n",
    "            elif phase == 'valid':\n",
    "                # 모델, 평가 모드 설정\n",
    "                model_mask.eval()\n",
    "\n",
    "            running_loss, running_corrects = 0.0, 0.0\n",
    "            num_cnt, f1, f1_scr = 0.0, 0.0, 0.0\n",
    "\n",
    "            if phase == 'train':\n",
    "                # 데이터 반복\n",
    "                for sample in tqdm.tqdm(train_dataloader):\n",
    "                    inputs = sample['image'].to(device)\n",
    "                    label = sample['label'].to(device)\n",
    "                    # 매개변수 경사도 0으로 설정\n",
    "                    optimizer_mask.zero_grad()\n",
    "\n",
    "                    # forward propagation (순전파)\n",
    "                    # 학습 시에서만, 연산 기록 추적\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model_mask(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, label)\n",
    "                        # 학습 단계에서만, 역전파 + 최적화\n",
    "                        loss.backward() # back propagation\n",
    "                        optimizer_mask.step() # optimize\n",
    "                        # 통계\n",
    "                        num_cnt += batch_size\n",
    "                        running_loss += loss.item()\n",
    "                        running_corrects += torch.sum(preds==label.data)\n",
    "                        f1_scr += f1_score(label.detach().cpu(), preds.detach().cpu(), average='macro')\n",
    "\n",
    "            elif phase == 'valid':\n",
    "                # 데이터 반복\n",
    "                for sample in tqdm.tqdm(train_dataloader):\n",
    "                    inputs = sample['image'].to(device)\n",
    "                    label = sample['label'].to(device)\n",
    "                    # 매개변수 경사도 0으로 설정\n",
    "                    optimizer_mask.zero_grad()\n",
    "\n",
    "                    # forward propagation (순전파)\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model_mask(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, label)\n",
    "                        # 통계\n",
    "                        num_cnt += batch_size\n",
    "                        running_loss += loss.item()\n",
    "                        running_corrects += torch.sum(preds==label.data)\n",
    "                        f1_scr += f1_score(label.detach().cpu(), preds.detach().cpu(),average='macro')\n",
    "\n",
    "\n",
    "#             if phase == 'train':\n",
    "#                 scheduler.step(running_loss)\n",
    "\n",
    "            epoch_loss = float(running_loss)\n",
    "            epoch_acc = float(running_corrects/num_cnt*100)\n",
    "            f1 = f1_scr/(num_cnt/batch_size)\n",
    "\n",
    "            # record in tensorboard\n",
    "            writer.add_scalar(f'Loss/{phase}', epoch_loss, epoch)\n",
    "            writer.add_scalar(f'Accuracy/{phase}', epoch_acc, epoch)\n",
    "            writer.add_scalar(f'F1-Score/{phase}', f1, epoch)\n",
    "\n",
    "            print(\n",
    "                f'{phase} loss_mask: {epoch_loss:.4f} Acc_mask: {epoch_acc:.4f} F1_score: {f1:.4f}'\n",
    "            )\n",
    "\n",
    "            # deep copy model\n",
    "            if phase == 'valid' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "#                 if phase == 'valid' and f1 >= best_f1:\n",
    "#                     best_f1 = f1\n",
    "                best_model_mask = copy.deepcopy(model_mask.state_dict())\n",
    "                torch.save(best_model_mask, f'best_model_mask{nums}.pth')\n",
    "                print('best_model_mask save!')\n",
    "        print('-' * 20)\n",
    "                \n",
    "    return model_mask.state_dict()\n",
    "\n",
    "# FIX num_eopchs=1 - 20\n",
    "# FIX batch_size=32, 64\n",
    "# FIX learnig_rate=3e-4, 1e-4\n",
    "# FIX ef_net='efficientnet-b4', 'efficientnet-b3'\n",
    "for i in range(5):\n",
    "    print('=' * 20)\n",
    "    print(f'=== {i+1}/5 counts ===')\n",
    "    model_mask_current = train_mask(num_epochs=2, batch_size=64, learnig_rate=1e-4, ef_net='efficientnet-b3', nums=i)\n",
    "\n",
    "# model_mask_current = train_mask(num_epochs=10, batch_size=64, learnig_rate=1e-4, ef_net='efficientnet-b3', nums=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03df6426-f3b7-449a-bb82-f5ba3fd4cf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### TRAIN_AGE ####################\n",
    "\n",
    "def train_age(num_epochs=10, batch_size=16, learnig_rate=3e-4, ef_net='efficientnet-b4', nums=i):\n",
    "    writer = SummaryWriter(log_dir=f'./results/b3_age_64_1e_4-{nums}')\n",
    "#     writer = SummaryWriter(log_dir=f'./results/pp_b3_age_32_1e_10-{nums}')\n",
    "    \n",
    "    best_loss = 100\n",
    "#     best_f1 = 0.0\n",
    "    \n",
    "    # FIX focal loss 사용해보기\n",
    "#     criterion = nn.CrossEntropyLoss().to(device)\n",
    "    criterion = FocalLoss(weight=weighted_age).to(device)\n",
    "    \n",
    "    # 모델(구조)만 가져오기\n",
    "    # model_age = EfficientNet.from_name(ef_net, num_classes=3).to(device)\n",
    "    # 이미 학습된 weight까지 가져오기\n",
    "    # num_classes: 데이터 분류 사이즈\n",
    "    model_age = EfficientNet.from_pretrained(ef_net, num_classes=3).to(device)\n",
    "    optimizer_age = optim.Adam(model_age.parameters(), lr=learnig_rate)\n",
    "    # 성능 향상 없을 때, learning rate 감소\n",
    "    # scheduler = optim.lr_scheduler.StepLR(optimizer_age, step_size=2, gamma=0.1)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer_age, mode='min', factor=0.2, patience=3\n",
    "    )\n",
    "\n",
    "    # KFold\n",
    "#     kfold = KFold(n_splits=5, shuffle=True)\n",
    "#     for fold, [train_ids, valid_ids] in enumerate(kfold.split(label_df)):\n",
    "#         if fold==1:\n",
    "#             return model_age.state_dict()\n",
    "        \n",
    "#     train_ids, valid_ids = get_index()\n",
    "    train_ids, valid_ids = get_index_label()\n",
    "\n",
    "#         train_data = age_dataset(label_df, index=[train_ids], transforms=age_transforms)\n",
    "#         valid_data = age_dataset(label_df, index=valid_ids, transforms=valid_transforms)\n",
    "    train_data = age_dataset(label_df, index=[i for i in range(2700*7)], transforms=age_transforms)\n",
    "    valid_data = age_dataset(label_df, index=valid_ids[4], transforms=valid_transforms)\n",
    "\n",
    "    # RandomSampler: Samples elements randomly\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    valid_sampler = RandomSampler(valid_data)\n",
    "\n",
    "    # num_workers: 데이터 로드 멀티 프로세싱\n",
    "    train_dataloader = DataLoader(\n",
    "        train_data, batch_size=batch_size,\n",
    "        shuffle=False, sampler=train_sampler, num_workers=4\n",
    "    )\n",
    "    valid_dataloader = DataLoader(\n",
    "        valid_data, batch_size=batch_size,\n",
    "        shuffle=False,  sampler=valid_sampler, num_workers=4\n",
    "    )\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 20)\n",
    "\n",
    "        # 각 epoch: 학습 단게, 검증 단계\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                # 모델, 학습 모드 설정\n",
    "                model_age.train()\n",
    "\n",
    "            elif phase == 'valid':\n",
    "                # 모델, 평가 모드 설정\n",
    "                model_age.eval()\n",
    "\n",
    "            running_loss, running_corrects = 0.0, 0.0\n",
    "            num_cnt, f1, f1_scr = 0.0, 0.0, 0.0\n",
    "\n",
    "            if phase == 'train':\n",
    "                # 데이터 반복\n",
    "                for sample in tqdm.tqdm(train_dataloader):\n",
    "                    inputs = sample['image'].to(device)\n",
    "                    label = sample['label'].to(device)\n",
    "                    # 매개변수 경사도 0으로 설정\n",
    "                    optimizer_age.zero_grad()\n",
    "\n",
    "                    # forward propagation (순전파)\n",
    "                    # 학습 시에서만, 연산 기록 추적\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model_age(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, label)\n",
    "                        # 학습 단계에서만, 역전파 + 최적화\n",
    "                        loss.backward() # back propagation\n",
    "                        optimizer_age.step() # optimize\n",
    "                        # 통계\n",
    "                        num_cnt += batch_size\n",
    "                        running_loss += loss.item()\n",
    "                        running_corrects += torch.sum(preds==label.data)\n",
    "                        f1_scr += f1_score(label.detach().cpu(), preds.detach().cpu(),average='macro')\n",
    "\n",
    "            elif phase == 'valid':\n",
    "                # 데이터 반복\n",
    "                for sample in tqdm.tqdm(train_dataloader):\n",
    "                    inputs = sample['image'].to(device)\n",
    "                    label = sample['label'].to(device)\n",
    "                    # 매개변수 경사도 0으로 설정\n",
    "                    optimizer_age.zero_grad()\n",
    "\n",
    "                    # forward propagation (순전파)\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model_age(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, label)\n",
    "                        # 통계\n",
    "                        num_cnt += batch_size\n",
    "                        running_loss += loss.item()\n",
    "                        running_corrects += torch.sum(preds==label.data)\n",
    "                        f1_scr += f1_score(label.detach().cpu(), preds.detach().cpu(),average='macro')\n",
    "\n",
    "#             if phase == 'train':\n",
    "#                 scheduler.step(running_loss)\n",
    "\n",
    "            epoch_loss = float(running_loss)\n",
    "            epoch_acc = float(running_corrects/num_cnt*100)\n",
    "            f1 = f1_scr/(num_cnt/batch_size)\n",
    "\n",
    "            # record in tensorboard\n",
    "            writer.add_scalar(f'Loss/{phase}', epoch_loss, epoch)\n",
    "            writer.add_scalar(f'Accuracy/{phase}', epoch_acc, epoch)\n",
    "            writer.add_scalar(f'F1-Score/{phase}', f1, epoch)\n",
    "\n",
    "            print(\n",
    "                f'{phase} loss_age: {epoch_loss:.4f} Acc_age: {epoch_acc:.4f} F1_score: {f1:.4f}'\n",
    "            )\n",
    "\n",
    "            # deep copy model\n",
    "            if phase == 'valid' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "#                 if phase == 'valid' and f1 >= best_f1:\n",
    "#                     best_f1 = f1\n",
    "                best_model_age = copy.deepcopy(model_age.state_dict())\n",
    "                torch.save(best_model_age, f'best_model_age{nums}.pth')\n",
    "                print('best_model_age save!')\n",
    "        print('-' * 20)\n",
    "\n",
    "    return model_age.state_dict()\n",
    "\n",
    "# FIX num_eopchs=1 - 20\n",
    "# FIX batch_size=32, 64\n",
    "# FIX learnig_rate=3e-4, 1e-4\n",
    "# FIX ef_net='efficientnet-b4', 'efficientnet-b3'\n",
    "for i in range(5):\n",
    "    print('=' * 20)\n",
    "    print(f'=== {i+1}/5 counts ===')\n",
    "    model_age_current = train_age(num_epochs=4, batch_size=64, learnig_rate=1e-4, ef_net='efficientnet-b3', nums=i)\n",
    "\n",
    "# model_age_current = train_age(num_epochs=10, batch_size=64, learnig_rate=1e-4, ef_net='efficientnet-b3', nums=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78086a4d-e3b2-4b14-8bbf-b2942f4acf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache() # GPU 캐시 데이터 삭제\n",
    "!free -mh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7657229-3905-479e-8a44-a81d771879d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### TRAIN_GENDER ####################\n",
    "\n",
    "def train_gender(num_epochs=10, batch_size=16, learnig_rate=3e-4, ef_net='efficientnet-b4', nums=i):\n",
    "    writer = SummaryWriter(log_dir=f'./results/b3_gender_64_1e_4-{nums}')\n",
    "#     writer = SummaryWriter(log_dir=f'./results/pp_b3_gender_64_1e_7-{nums}')\n",
    "        \n",
    "    best_loss = 100\n",
    "#     best_f1 = 0.0\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(weight=weighted_gender).to(device)\n",
    "    \n",
    "    # 모델(구조)만 가져오기\n",
    "    # model_gender = EfficientNet.from_name(ef_net, num_classes=2).to(device)\n",
    "    # 이미 학습된 weight까지 가져오기\n",
    "    # num_classes: 데이터 분류 사이즈\n",
    "    model_gender = EfficientNet.from_pretrained(ef_net, num_classes=2).to(device)\n",
    "    optimizer_gender = optim.Adam(model_gender.parameters(), lr=learnig_rate)\n",
    "    \n",
    "    # 성능 향상 없을 때, learning rate 감소\n",
    "    # scheduler = optim.lr_scheduler.StepLR(optimizer_gender, step_size=3, gamma=0.1)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer_gender, mode='min', factor=0.2, patience=3\n",
    "    )\n",
    "\n",
    "    # KFold\n",
    "#     kfold = KFold(n_splits=5, shuffle=True)\n",
    "#     for fold, [train_ids, valid_ids] in enumerate(kfold.split(label_df)):\n",
    "#         if fold==1:\n",
    "#             return model_gender.state_dict()\n",
    "\n",
    "#     train_ids, valid_ids = get_index()\n",
    "    train_ids, valid_ids = get_index_label()\n",
    "\n",
    "#         train_data = gender_dataset(label_df, index=[train_ids], transforms=gender_transforms)\n",
    "#         valid_data = gender_dataset(label_df, index=valid_ids, transforms=valid_transforms)\n",
    "    train_data = gender_dataset(label_df, index=[i for i in range(2700*7)], transforms=gender_transforms)\n",
    "    valid_data = gender_dataset(label_df, index=valid_ids[4], transforms=valid_transforms)\n",
    "\n",
    "    # RandomSampler: Samples elements randomly\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    valid_sampler = RandomSampler(valid_data)\n",
    "\n",
    "    # num_workers: 데이터 로드 멀티 프로세싱\n",
    "    train_dataloader = DataLoader(\n",
    "        train_data, batch_size=batch_size,\n",
    "        shuffle=False, sampler=train_sampler, num_workers=4\n",
    "    )\n",
    "    valid_dataloader = DataLoader(\n",
    "        valid_data, batch_size=batch_size,\n",
    "        shuffle=False, sampler=valid_sampler, num_workers=4\n",
    "    )\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 20)\n",
    "\n",
    "        # 각 epoch: 학습 단게, 검증 단계\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                # 모델, 학습 모드 설정\n",
    "                model_gender.train()\n",
    "\n",
    "            elif phase == 'valid':\n",
    "                # 모델, 평가 모드 설정\n",
    "                model_gender.eval()\n",
    "\n",
    "            running_loss, running_corrects = 0.0, 0.0\n",
    "            num_cnt, f1, f1_scr = 0.0, 0.0, 0.0\n",
    "\n",
    "            if phase == 'train':\n",
    "                # 데이터 반복\n",
    "                for sample in tqdm.tqdm(train_dataloader):\n",
    "                    inputs = sample['image'].to(device)\n",
    "                    label = sample['label'].to(device)\n",
    "                    # 매개변수 경사도 0으로 설정\n",
    "                    optimizer_gender.zero_grad()\n",
    "\n",
    "                    # forward propagation (순전파)\n",
    "                    # 학습 시에서만, 연산 기록 추적\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model_gender(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, label)\n",
    "                        # 학습 단계에서만, 역전파 + 최적화\n",
    "                        loss.backward() # back propagation\n",
    "                        optimizer_gender.step() # optimize\n",
    "                        # 통계\n",
    "                        num_cnt += batch_size\n",
    "                        running_loss += loss.item()\n",
    "                        running_corrects += torch.sum(preds==label.data)\n",
    "                        f1_scr += f1_score(label.detach().cpu(), preds.detach().cpu(), average='macro')\n",
    "\n",
    "            elif phase == 'valid':\n",
    "                # 데이터 반복\n",
    "                for sample in tqdm.tqdm(train_dataloader):\n",
    "                    inputs = sample['image'].to(device)\n",
    "                    label = sample['label'].to(device)\n",
    "                    # 매개변수 경사도 0으로 설정\n",
    "                    optimizer_gender.zero_grad()\n",
    "\n",
    "                    # forward propagation (순전파)\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model_gender(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, label)\n",
    "                        # 통계\n",
    "                        num_cnt += batch_size\n",
    "                        running_loss += loss.item()\n",
    "                        running_corrects += torch.sum(preds==label.data)\n",
    "                        f1_scr += f1_score(label.detach().cpu(), preds.detach().cpu(),average='macro')\n",
    "\n",
    "\n",
    "#             if phase == 'train':\n",
    "#                 scheduler.step(running_loss)\n",
    "\n",
    "            epoch_loss = float(running_loss)\n",
    "            epoch_acc = float(running_corrects/num_cnt*100)\n",
    "            f1 = f1_scr/(num_cnt/batch_size)\n",
    "\n",
    "            # record in tensorboard\n",
    "            writer.add_scalar(f'Loss/{phase}', epoch_loss, epoch)\n",
    "            writer.add_scalar(f'Accuracy/{phase}', epoch_acc, epoch)\n",
    "            writer.add_scalar(f'F1-Score/{phase}', f1, epoch)\n",
    "\n",
    "            print(\n",
    "                f'{phase} loss_gender: {epoch_loss:.4f} Acc_gender: {epoch_acc:.4f} F1_score: {f1:.4f}'\n",
    "            )\n",
    "\n",
    "            # deep copy model\n",
    "            if phase == 'valid' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "#                 if phase == 'valid' and f1 >= best_f1:\n",
    "#                     best_f1 = f1\n",
    "                best_model_gender = copy.deepcopy(model_gender.state_dict())\n",
    "                torch.save(best_model_gender, f'best_model_gender{nums}.pth')\n",
    "                print('best_model_gender save!')\n",
    "        print('-' * 20)\n",
    "                \n",
    "    return model_gender.state_dict()\n",
    "\n",
    "# FIX num_eopchs=1 - 20\n",
    "# FIX batch_size=32, 64\n",
    "# FIX learnig_rate=3e-4, 1e-4\n",
    "# FIX ef_net='efficientnet-b4', 'efficientnet-b3'\n",
    "for i in range(5):\n",
    "    print('=' * 20)\n",
    "    print(f'=== {i+1}/5 counts ===')\n",
    "    model_gender_current = train_gender(num_epochs=4, batch_size=64, learnig_rate=1e-4, ef_net='efficientnet-b3', nums=i)\n",
    "    \n",
    "# model_gender_current = train_gender(num_epochs=10, batch_size=64, learnig_rate=1e-4, ef_net='efficientnet-b3', nums=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16b61ed-825b-4c8b-a0f4-bdc2cef1ffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# order in [mask, age, gender]\n",
    "# mask: wear: 2, incorrect: 1, normal: 0\n",
    "# age: - 29: 0, 30 - 59: 1, 60 - : 2\n",
    "# gender: female: 0, male: 1\n",
    "\n",
    "classes = {\n",
    "    '201': 0, '211': 1, '221': 2,\n",
    "    '200': 3, '210': 4, '220': 5,\n",
    "    '101': 6, '111': 7, '121': 8,\n",
    "    '100': 9, '110': 10, '120': 11,\n",
    "    '001': 12, '011': 13, '021': 14,\n",
    "    '000': 15, '010': 16, '020': 17\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3fbb81-6313-444e-90a7-7939e8273802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### TEST_DATASETS ####################\n",
    "\n",
    "class dataset_test(Dataset):\n",
    "    def __init__(self, data, transforms=None):\n",
    "        self.data = data\n",
    "        self.transforms=transforms\n",
    "        self.path = './input/data/eval/new_imgs'\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx, 0]\n",
    "        img = cv2.imread(os.path.join(self.path, img_path))\n",
    "        image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image=image)['image']\n",
    "        image = image.transpose((2,0,1))\n",
    "        sample = {'image': image}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc3c0fa-2df8-4432-9f8d-a1da2d3a10ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### TEST_PREPARE ####################\n",
    "### ???\n",
    "### 성능 더 좋아지기는 한데, 이렇게 해도 되는 건지는 의문...\n",
    "\n",
    "for i in range(5):\n",
    "    globals()[f'model_mask{i}'] = EfficientNet.from_name('efficientnet-b3', num_classes=3).to(device)\n",
    "    globals()[f'model_age{i}'] = EfficientNet.from_name('efficientnet-b3', num_classes=3).to(device)\n",
    "    globals()[f'model_gender{i}'] = EfficientNet.from_name('efficientnet-b3', num_classes=2).to(device)\n",
    "    \n",
    "# model_mask0 = EfficientNet.from_name('efficientnet-b3', num_classes=3).to(device)\n",
    "# model_mask1 = EfficientNet.from_name('efficientnet-b3', num_classes=3).to(device)\n",
    "# model_mask2 = EfficientNet.from_name('efficientnet-b3', num_classes=3).to(device)\n",
    "# model_mask3 = EfficientNet.from_name('efficientnet-b3', num_classes=3).to(device)\n",
    "# model_mask4 = EfficientNet.from_name('efficientnet-b3', num_classes=3).to(device)\n",
    "\n",
    "# model_age0 = EfficientNet.from_name('efficientnet-b3', num_classes=3).to(device)\n",
    "# model_age1 = EfficientNet.from_name('efficientnet-b3', num_classes=3).to(device)\n",
    "# model_age2 = EfficientNet.from_name('efficientnet-b3', num_classes=3).to(device)\n",
    "# model_age3 = EfficientNet.from_name('efficientnet-b3', num_classes=3).to(device)\n",
    "# model_age4 = EfficientNet.from_name('efficientnet-b3', num_classes=3).to(device)\n",
    "\n",
    "# model_gender0 = EfficientNet.from_name('efficientnet-b3', num_classes=2).to(device)\n",
    "# model_gender1 = EfficientNet.from_name('efficientnet-b3', num_classes=2).to(device)\n",
    "# model_gender2 = EfficientNet.from_name('efficientnet-b3', num_classes=2).to(device)\n",
    "# model_gender3 = EfficientNet.from_name('efficientnet-b3', num_classes=2).to(device)\n",
    "# model_gender4 = EfficientNet.from_name('efficientnet-b3', num_classes=2).to(device)\n",
    "\n",
    "for i in range(5):\n",
    "    eval(f'model_mask{i}').load_state_dict(torch.load(f'./best_model_mask{i}.pth'))\n",
    "    eval(f'model_age{i}').load_state_dict(torch.load(f'./best_model_age{i}.pth'))\n",
    "    eval(f'model_gender{i}').load_state_dict(torch.load(f'./best_model_gender{i}.pth'))\n",
    "\n",
    "# model_mask0.eval()\n",
    "# model_age0.eval()\n",
    "# model_gender0.eval()\n",
    "\n",
    "models_mask = list()\n",
    "# models_mask.extend([model_mask0, model_mask1, model_mask2, model_mask3, model_mask4])\n",
    "models_mask.extend([eval(f'model_mask{i}') for i in range(5)])\n",
    "\n",
    "models_age = list()\n",
    "# models_age.extend([model_age0, model_age1, model_age2, model_age3, model_age4])\n",
    "models_age.extend([eval(f'model_age{i}') for i in range(5)])\n",
    "\n",
    "models_gender = list()\n",
    "# models_gender.extend([model_gender0, model_gender1, model_gender2, model_gender3, model_gender4])\n",
    "models_gender.extend([eval(f'model_gender{i}') for i in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747ac4dc-df60-4867-95da-1a0c7d213e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### TEST ####################\n",
    "\n",
    "test_data = pd.read_csv('./input/data/eval/info.csv')\n",
    "submission = pd.read_csv('./input/data/eval/info.csv')\n",
    "\n",
    "test_dataset = dataset_test(test_data, transforms=valid_transforms)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "total_result = list()\n",
    "\n",
    "for sample in tqdm.tqdm(test_dataloader):\n",
    "    with torch.no_grad():\n",
    "        inputs = sample['image'].to(device)\n",
    "        \n",
    "#         output_mask = model_mask0(inputs)\n",
    "#         output_age = model_age0(inputs)\n",
    "#         output_gender = model_gender0(inputs)\n",
    "\n",
    "        output_mask = 0\n",
    "        output_age = 0\n",
    "        output_gender = 0\n",
    "        \n",
    "        for model in models_mask:\n",
    "            model.eval()\n",
    "            output_mask += model(inputs)\n",
    "            \n",
    "        for model in models_age:\n",
    "            model.eval()\n",
    "            output_age += model(inputs)\n",
    "            \n",
    "        for model in models_gender:\n",
    "            model.eval()\n",
    "            output_gender += model(inputs)\n",
    "        \n",
    "        _, preds_mask = torch.max(output_mask, 1)\n",
    "        _, preds_age = torch.max(output_age, 1)\n",
    "        _, preds_gender = torch.max(output_gender, 1)\n",
    "        \n",
    "        for mask, age, gender in zip(preds_mask, preds_age, preds_gender):\n",
    "            ans = list()\n",
    "            ans.append(mask.detach().cpu().numpy().astype('|S1').tobytes().decode('utf-8'))\n",
    "            ans.append(age.detach().cpu().numpy().astype('|S1').tobytes().decode('utf-8'))\n",
    "            ans.append(gender.detach().cpu().numpy().astype('|S1').tobytes().decode('utf-8'))\n",
    "            dt = ''.join(ans)\n",
    "            \n",
    "            total_result.append(classes[dt])\n",
    "            \n",
    "submission['ans'] = total_result\n",
    "submission.to_csv('./submission10.csv', index=False)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44539cca-bdbe-4c21-a163-2ea89afafca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cdf5ab-8b12-4974-80b5-756ef0883915",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### VALID_DATASETS ####################\n",
    "\n",
    "class dataset_valid(Dataset):\n",
    "    def __init__(self, data, transforms=None):\n",
    "        self.data = data\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx, 0]\n",
    "        label_mask = int(self.data.iloc[idx, 1])\n",
    "        label_age = int(self.data.iloc[idx, 2])\n",
    "        label_gender = int(self.data.iloc[idx, 3])\n",
    "        \n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image=img)['image']\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        \n",
    "        sample = {'image':image, 'label_mask':label_mask,'label_age':label_age,'label_gender':label_gender}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffcde28-9ad7-4a49-b451-fb8359e246fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### F1_Score ####################\n",
    "\n",
    "valid_test_data = dataset_valid(data.iloc[int(len(data)*0.8):, :], transforms=valid_transforms)\n",
    "valid_dataloader = DataLoader(valid_test_data, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "f1 = 0\n",
    "f1_sc = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample in tqdm.tqdm(valid_dataloader):\n",
    "        inputs = sample['image'].to(device)\n",
    "        \n",
    "        output_mask = model_mask0(inputs)\n",
    "        output_age = model_age0(inputs)\n",
    "        output_gender = model_gender0(inputs)\n",
    "        \n",
    "#         output_mask = 0\n",
    "#         output_age = 0\n",
    "#         output_gender = 0\n",
    "        \n",
    "#         for model in models_mask:\n",
    "#             output_mask += model(inputs)\n",
    "            \n",
    "#         for model in models_age:\n",
    "#             output_age += model(inputs)\n",
    "            \n",
    "#         for model in models_gender:\n",
    "#             output_gender += model(inputs)\n",
    "    \n",
    "        _, preds_mask = torch.max(output_mask, 1)\n",
    "        _, preds_age = torch.max(output_age, 1)\n",
    "        _, preds_gender = torch.max(output_gender, 1)\n",
    "        \n",
    "        for mask, age, gender, label_mask, label_age, label_gender in zip(\n",
    "            preds_mask, preds_age, preds_gender,\n",
    "            sample['label_mask'], sample['label_age'], sample['label_gender']\n",
    "        ):\n",
    "            ans = list()\n",
    "            label = list()\n",
    "            \n",
    "            ans.append(mask.detach().cpu().numpy().astype('|S1').tobytes().decode('utf-8'))\n",
    "            ans.append(age.detach().cpu().numpy().astype('|S1').tobytes().decode('utf-8'))\n",
    "            ans.append(gender.detach().cpu().numpy().astype('|S1').tobytes().decode('utf-8'))\n",
    "            dt = ''.join(ans)   \n",
    "            \n",
    "            label.append(label_mask.detach().cpu().numpy().astype('|S1').tobytes().decode('utf-8'))\n",
    "            label.append(label_age.detach().cpu().numpy().astype('|S1').tobytes().decode('utf-8'))\n",
    "            label.append(label_gender.detach().cpu().numpy().astype('|S1').tobytes().decode('utf-8'))\n",
    "            lb = ''.join(label)\n",
    "            \n",
    "            ans = np.zeros((18, ))\n",
    "            pred = np.zeros((18, ))\n",
    "            \n",
    "            ans[classes[lb]] = 1\n",
    "            pred[classes[dt]] = 1\n",
    "            \n",
    "            f1_sc += f1_score(ans, pred, average='macro')\n",
    "\n",
    "print(f1_sc/(len(data) * 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef98e7d4-4d94-44b9-84ce-fcd56754734a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
