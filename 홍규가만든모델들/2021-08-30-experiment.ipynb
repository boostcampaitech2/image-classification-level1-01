{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Libarary 불러오기 및 경로설정"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os\r\n",
    "import pandas as pd\r\n",
    "from PIL import Image\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "from torch.utils.data import Dataset, DataLoader\r\n",
    "from glob import glob\r\n",
    "import torchvision\r\n",
    "from torchvision import transforms\r\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\r\n",
    "\r\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# A = torch.tensor([[100,1000,1],[1,1,10]])\r\n",
    "# b = torch.argmax(A, dim=1) \r\n",
    "# c = torch.tensor([0,2])\r\n",
    "# torch.tensor(b==c)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipykernel_40057/2434658839.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(b==c)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([False,  True])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## test관련 세팅\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# 테스트 데이터셋 폴더 경로를 지정해주세요.\r\n",
    "test_dir = os.path.join(os.getcwd() , 'datasets/eval/')\r\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\r\n",
    "image_dir = os.path.join(test_dir, 'images')\r\n",
    "\r\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\r\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID] #imgDirList\r\n",
    "# 이미지 주소 리스트를 반환해줌\r\n",
    "\r\n",
    "transforms_test = transforms.Compose([\r\n",
    "    transforms.Resize((224, 224)),\r\n",
    "    #transforms.RandomHorizontalFlip(), #Data Augmentation 데이터 증진?!\r\n",
    "    transforms.ToTensor(),\r\n",
    "    transforms.Normalize(\r\n",
    "        [0.485, 0.456, 0.406],\r\n",
    "        [0.229, 0.224, 0.225],\r\n",
    "    ),\r\n",
    "])\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "transforms_train = transforms.Compose([\r\n",
    "    transforms.Resize((224, 224)),\r\n",
    "    transforms.RandomHorizontalFlip(), #Data Augmentation 데이터 증진?!\r\n",
    "    transforms.ToTensor(),\r\n",
    "    transforms.Normalize(\r\n",
    "        [0.485, 0.456, 0.406],\r\n",
    "        [0.229, 0.224, 0.225],\r\n",
    "    ),\r\n",
    "])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Model 정의"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "\r\n",
    "\r\n",
    "gender_classifier = torchvision.models.resnet34(pretrained=True)\r\n",
    "gender_classifier.fc = torch.nn.Sequential(\r\n",
    "    nn.Linear(in_features=512, out_features=2, bias=True),\r\n",
    "    nn.Sigmoid(),\r\n",
    ")#age는 선형회귀로 만들어보기\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1 style=\"color='blue'\">Train Dataset 정의</h1>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class Train_Datasets (torch.utils.data.Dataset):\r\n",
    "    _train_csv = pd.read_csv('./datasets/train/train.csv')\r\n",
    "    dir_list=  glob('./datasets/train/images/*/*')\r\n",
    "    \r\n",
    "\r\n",
    "    def __len__ (self):\r\n",
    "        return self.dir_list.__len__()\r\n",
    "    \r\n",
    "    def __getitem__ (self , idx):\r\n",
    "        dir = self.dir_list[idx],\r\n",
    "        _wear = ''\r\n",
    "        if self.dir_list[idx].split('/')[-1].startswith('mask') :\r\n",
    "            _wear = 2\r\n",
    "        elif self.dir_list[idx].split('/')[-1].startswith('inc'):\r\n",
    "            _wear = 1\r\n",
    "        else : \r\n",
    "            _wear = 0\r\n",
    "        id, gender, _ , age = self.dir_list[idx].split('/')[-2].split('_')\r\n",
    "        gender = 0 if gender == 'female' else 1\r\n",
    "        img = Image.open(self.dir_list[idx]) #해당 주소로 이미지 열고\r\n",
    "        X = transforms_train(img)\r\n",
    "        age = int(age)\r\n",
    "        if age <30 :\r\n",
    "            age = 0 \r\n",
    "        elif age >= 30 and age <60 :\r\n",
    "            age =1\r\n",
    "        else:\r\n",
    "            age=2\r\n",
    "\r\n",
    "        #.unsqueeze(0)  if transforms_train(img).shape.__len__() == 3 else  transforms_train(img)# 트랜스폼에 전달해서 텐서화\r\n",
    "        y = (\r\n",
    "            torch.tensor(gender), \r\n",
    "            torch.tensor(_wear), \r\n",
    "            torch.tensor(age)\r\n",
    "        ) #y는 우리가 모델로 판별하고자 하는 요소들, 젠더, 마스크착용형태, age\r\n",
    "        return X, y\r\n",
    "\r\n",
    "# y는 gender , 마스크 착용여부, 나이 \r\n",
    "# gender는 여자가 0, 남자가 1\r\n",
    "# 마스크는 제대로 쓰면 2, 이상하게 쓰면 1, 안쓰면 ,0\r\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_datasets = Train_Datasets()\r\n",
    "train_databatch = torch.utils.data.DataLoader(\r\n",
    "    train_datasets,\r\n",
    "    batch_size = 100,\r\n",
    "    shuffle = True,\r\n",
    "    num_workers = 4,\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. 마스크 분류모델 모델\n",
    "### 라벨링\n",
    "- <mark>[미착용, 오착용, 정상착용]</mark> 순서로 라벨링 되어 있음."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# 1. 모델의 정의\r\n",
    "# 전이학습 모델로 만듦\r\n",
    "mask_classifier = torchvision.models.resnet34(pretrained=True)\r\n",
    "mask_classifier.fc = nn.Sequential(\r\n",
    "    nn.Linear(in_features = 512, out_features = 3, bias=True),\r\n",
    "    nn.Softmax(),\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# 🌊텐서보드 관련\r\n",
    "writer = SummaryWriter()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 2. 학습모드\r\n",
    "epochs = 1\r\n",
    "def mask_criterion (pred, y):\r\n",
    "    #마스크는 3가지 클래스로 분류.\r\n",
    "    #즉 실제 정답 y는 0,1,2 셋 중 하나를 값으로 가짐.\r\n",
    "    pred = -1 * torch.log2(pred) # 모델이 예측한 클래스별 확률(=pred) 전체에 로그를 씌움.... \r\n",
    "    pred = 0.025 * pred # 0.025를 일단 곱해주자. 왜냐하면 일종의 라벨 스무딩임...\r\n",
    "    # 라벨에 해당되는 원소는 0.95/0.025=38를 곱해주자.\r\n",
    "    for idx, label in enumerate(y): #y로 반복문(for)을 돌리자.\r\n",
    "        pred[idx,label ] = 38 * pred[idx,label ]\r\n",
    "    \r\n",
    "    return torch.sum(pred)\r\n",
    "    \r\n",
    "mask_opti =torch.optim.Adam(mask_classifier.parameters(), lr=0.001)\r\n",
    "device = torch.device('cuda')\r\n",
    "mask_classifier.to(device).train()\r\n",
    "\r\n",
    "for _i_d_x__ in range(epochs):\r\n",
    "    for i, ( X, y ) in enumerate(train_databatch):\r\n",
    "        X = X.to(device)\r\n",
    "        _ ,mask_real , __ = y\r\n",
    "        mask_real = mask_real.to(device)\r\n",
    "        print(mask_real)\r\n",
    "        mask_opti.zero_grad()\r\n",
    "        mask_pred = mask_classifier(X)     \r\n",
    "        print('모델 예측 값 ', mask_pred)\r\n",
    "        print('-'*50)\r\n",
    "        loss_mask = mask_criterion(mask_pred, mask_real)\r\n",
    "        print( i, 'mask _loss : ', loss_mask)\r\n",
    "        writer.add_scalar(\r\n",
    "            \"Loss/train\", \r\n",
    "            loss_mask, \r\n",
    "            i + train_datasets.__len__()*_i_d_x__\r\n",
    "        )\r\n",
    "        loss_mask.backward()\r\n",
    "        mask_opti.step()\r\n",
    "writer.flush()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!tensorboard --logdir=runs\r\n",
    "#writer.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Test 모드\r\n",
    "test_model = mask_classifier \r\n",
    "imglist = glob('./datasets/eval/images/*')\r\n",
    "transforms_test = transforms.Compose([\r\n",
    "    transforms.Resize((224, 224)),\r\n",
    "    transforms.ToTensor(),\r\n",
    "    transforms.Normalize(\r\n",
    "        [0.485, 0.456, 0.406],\r\n",
    "        [0.229, 0.224, 0.225],\r\n",
    "    ),\r\n",
    "])\r\n",
    "test_model = test_model.to(device)\r\n",
    "test_model.eval()\r\n",
    "with torch.no_grad() :\r\n",
    "    for idx, dir in enumerate(imglist):\r\n",
    "        print(dir)\r\n",
    "        if idx < 10 : \r\n",
    "            continue\r\n",
    "        if idx == 20 :\r\n",
    "            break\r\n",
    "        img = Image.open(dir)\r\n",
    "        plt.imshow(img)\r\n",
    "        img = transforms_test(img).to(torch.device('cuda'))\r\n",
    "        age_predict = test_model(img.unsqueeze(0))\r\n",
    "        plt.title(age_predict)\r\n",
    "        plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. 연령 분류 모델"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "age_classifier = torchvision.models.resnet34(pretrained=True)\r\n",
    "\r\n",
    "age_classifier.fc = nn.Sequential(\r\n",
    "    nn.Linear(in_features = 512, out_features = 3, bias=True),\r\n",
    "    nn.Softmax(),\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 2. 학습모드\r\n",
    "epochs = 1\r\n",
    "def age_criterion (pred, y):\r\n",
    "    #에이지 역시 3가지 클래스로 분류.\r\n",
    "    #즉 실제 정답 y는 0,1,2 셋 중 하나를 값으로 가짐.\r\n",
    "    pred = -1 * torch.log2(pred) # 모델이 예측한 클래스별 확률(=pred) 전체에 로그를 씌움.... \r\n",
    "    pred = 0.05 * pred # 0.05를 일단 곱해주자. 왜냐하면 일종의 라벨 스무딩임...\r\n",
    "    # 라벨에 해당되는 원소는 0.95/0.05=19를 곱해주자.\r\n",
    "    for idx, label in enumerate(y): #y로 반복문(for)을 돌리자.\r\n",
    "        pred[idx,label ] = 19 * pred[idx,label ]\r\n",
    "    \r\n",
    "    return torch.sum(pred)\r\n",
    "    \r\n",
    "age_opti =torch.optim.Adam(age_classifier.parameters(), lr=0.001)\r\n",
    "device = torch.device('cuda')\r\n",
    "age_classifier.to(device).train()\r\n",
    "\r\n",
    "correct_count = 0\r\n",
    "for _ in range(epochs):\r\n",
    "    \r\n",
    "    for i, (X, y) in enumerate(train_databatch):\r\n",
    "        X = X.to(device)\r\n",
    "        _ ,__ , age_real = y\r\n",
    "        age_real = age_real.to(device)\r\n",
    "        \r\n",
    "        # print(age_real)\r\n",
    "        \r\n",
    "        age_opti.zero_grad()\r\n",
    "        age_pred = age_classifier(X)   \r\n",
    "\r\n",
    "        how_much = torch.sum(torch.argmax(age_pred, dim=1) == age_real).item()\r\n",
    "        print(\r\n",
    "            i, \r\n",
    "            \"번째 배치에서의 정답률\",\r\n",
    "            how_much,\r\n",
    "            \"%\",\r\n",
    "        )\r\n",
    "        correct_count += how_much\r\n",
    "\r\n",
    "        # print('모델 예측 값 ', age_pred)\r\n",
    "        # print('-'*50)\r\n",
    "        loss_age = age_criterion(age_pred, age_real)\r\n",
    "        # print( i, 'mask _loss : ', loss_age)\r\n",
    "        loss_age.backward()\r\n",
    "        age_opti.step()\r\n",
    "print('모델 정확도 : ', correct_count/train_datasets.__len__())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Test 모드\r\n",
    "test_model = age_classifier \r\n",
    "imglist = glob('./datasets/eval/images/*')\r\n",
    "transforms_test = transforms.Compose([\r\n",
    "    transforms.Resize((224, 224)),\r\n",
    "    transforms.ToTensor(),\r\n",
    "    transforms.Normalize(\r\n",
    "        [0.485, 0.456, 0.406],\r\n",
    "        [0.229, 0.224, 0.225],\r\n",
    "    ),\r\n",
    "])\r\n",
    "test_model = test_model.to(device)\r\n",
    "test_model.eval()\r\n",
    "with torch.no_grad() :\r\n",
    "    for idx, dir in enumerate(imglist):\r\n",
    "        print(dir)\r\n",
    "        if idx < 10 : \r\n",
    "            continue\r\n",
    "        if idx == 20 :\r\n",
    "            break\r\n",
    "        img = Image.open(dir)\r\n",
    "        plt.imshow(img)\r\n",
    "        img = transforms_test(img).to(torch.device('cuda'))\r\n",
    "        age_predict = test_model(img.unsqueeze(0))\r\n",
    "        plt.title(age_predict)\r\n",
    "        plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. 젠더 분류 모델"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "gender_classifier = torchvision.models.resnet34(pretrained=True)\r\n",
    "\r\n",
    "gender_classifier.fc = nn.Sequential(\r\n",
    "    nn.Linear(in_features = 512, out_features = 2, bias=True),\r\n",
    "    nn.Softmax(),\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 2. 학습모드\r\n",
    "epochs = 1\r\n",
    "def gender_criterion (pred, y):\r\n",
    "    #에이지 역시 3가지 클래스로 분류.\r\n",
    "    #즉 실제 정답 y는 0,1,2 셋 중 하나를 값으로 가짐.\r\n",
    "    pred = -1 * torch.log2(pred) # 모델이 예측한 클래스별 확률(=pred) 전체에 로그를 씌움.... \r\n",
    "    pred = 0.025 * pred # 0.025를 일단 곱해주자. 왜냐하면 일종의 라벨 스무딩임...\r\n",
    "    # 라벨에 해당되는 원소는 0.975/0.025=39를 곱해주자.\r\n",
    "    for idx, label in enumerate(y): #y로 반복문(for)을 돌리자.\r\n",
    "        pred[idx,label ] = 39 * pred[idx,label ]\r\n",
    "    \r\n",
    "    return torch.sum(pred)\r\n",
    "    \r\n",
    "gender_opti =torch.optim.Adam(gender_classifier.parameters(), lr=0.001)\r\n",
    "device = torch.device('cuda')\r\n",
    "gender_classifier.to(device).train()\r\n",
    "\r\n",
    "\r\n",
    "correct_count = 0\r\n",
    "\r\n",
    "for _ in range(epochs):\r\n",
    "    for i,( X, y ) in enumerate( train_databatch):\r\n",
    "        X = X.to(device)\r\n",
    "        gender_real ,__ , _ = y\r\n",
    "        \r\n",
    "        gender_real = gender_real.to(device)\r\n",
    "        # print(\"실제 성별 : \" ,gender_real)\r\n",
    "        gender_opti.zero_grad()\r\n",
    "        gender_pred = gender_classifier(X)    \r\n",
    "        \r\n",
    "\r\n",
    "        how_much = torch.sum( torch.argmax(gender_pred, dim=1) == gender_real).item()\r\n",
    "        print(\r\n",
    "            i, \r\n",
    "            \"번째 배치에서의 정답률\", \r\n",
    "            how_much,\r\n",
    "            '%',\r\n",
    "        )\r\n",
    "\r\n",
    "        correct_count += how_much\r\n",
    "\r\n",
    "        # print('모델 예측 값 ', gender_pred)\r\n",
    "        # print('-'*50)\r\n",
    "        loss_gender = gender_criterion(gender_pred, gender_real)\r\n",
    "        print('배치: ', i, '// gender _loss : ', loss_gender.item())\r\n",
    "        loss_gender.backward()\r\n",
    "        gender_opti.step()\r\n",
    "\r\n",
    "print(\r\n",
    "    \"모델 정확도 :\", \r\n",
    "    correct_count/train_datasets.__len__())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Test 모드\r\n",
    "test_model = gender_classifier \r\n",
    "imglist = glob('./datasets/eval/images/*')\r\n",
    "transforms_test = transforms.Compose([\r\n",
    "    transforms.Resize((224, 224)),\r\n",
    "    transforms.ToTensor(),\r\n",
    "    transforms.Normalize(\r\n",
    "        [0.485, 0.456, 0.406],\r\n",
    "        [0.229, 0.224, 0.225],\r\n",
    "    ),\r\n",
    "])\r\n",
    "test_model = test_model.to(device)\r\n",
    "test_model.eval()\r\n",
    "with torch.no_grad() :\r\n",
    "    for idx, dir in enumerate(imglist):\r\n",
    "        print(dir)\r\n",
    "        if idx < 10 : \r\n",
    "            continue\r\n",
    "        if idx == 20 :\r\n",
    "            break\r\n",
    "        img = Image.open(dir)\r\n",
    "        plt.imshow(img)\r\n",
    "        img = transforms_test(img).to(torch.device('cuda'))\r\n",
    "        age_predict = test_model(img.unsqueeze(0))\r\n",
    "        plt.title(age_predict)\r\n",
    "        plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Inference"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "device = torch.device('cuda')\r\n",
    "\r\n",
    "mask_classifier.eval()\r\n",
    "gender_classifier.eval()\r\n",
    "age_classifier.eval()\r\n",
    "\r\n",
    "all_predictions =[]\r\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\r\n",
    "for img_dir in image_paths:\r\n",
    "    img_obj = Image.open(img_dir)\r\n",
    "    img_obj = transforms_test(img_obj).unsqueeze(0).to(device)\r\n",
    "    with torch.no_grad():\r\n",
    "        img_obj = img_obj.to(device)\r\n",
    "        pred = model(img_obj)\r\n",
    "        pred = pred.argmax(dim=-1)\r\n",
    "        pred = pred.cpu().numpy()\r\n",
    "        idx_list = [0,1,10,11,12,13,14,15,16,17,2,3,4,5,6,7,8,9]\r\n",
    "        pred = idx_list[int(pred)]\r\n",
    "        all_predictions.append(pred)\r\n",
    "submission['ans'] = all_predictions\r\n",
    "\r\n",
    "# 제출할 파일을 저장합니다.\r\n",
    "submission.to_csv(os.path.join(test_dir, 'submission.csv'), index=False)\r\n",
    "print('test inference is done!')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test inference is done!\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}